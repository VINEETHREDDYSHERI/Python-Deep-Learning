{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP12-Question3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGKoOYBHyWTQ"
      },
      "source": [
        "# Importing the necessary libraries\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVK2XutLzfso",
        "outputId": "cd88435d-a405-4e7d-a857-25533b49bb76"
      },
      "source": [
        "# Connecting to google drive for accessing the Sentiment.csv and also to save model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVW03eHLxr8-",
        "outputId": "bb76448d-76ac-4585-d02c-4e8f43176867"
      },
      "source": [
        "# Loading the Sentiment dataset\n",
        "data = pd.read_csv('/content/gdrive/MyDrive/Deep Learning/ICP12/spam.csv',encoding=\"ISO-8859-1\")\n",
        "\n",
        "# Keeping only the columns that are required. v2 is input and v1 is the output. Remaining columns are empty.\n",
        "data = data[['v1', 'v2']]\n",
        "\n",
        "print(\"Before preprocessing: \\n\")\n",
        "print(data['v2'].head())\n",
        "# Applying pre-processing task\n",
        "# Converting all the characters to lower case\n",
        "data['v2'] = data['v2'].apply(lambda x: x.lower())\n",
        "# Making using of Regular expression to remove unwanted data like @ / ' # . etc.\n",
        "data['v2'] = data['v2'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n",
        "\n",
        "# Removing 'rt' string that is persent in all the text.\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')\n",
        "\n",
        "print(\"\\n After preprocessing: \\n\")\n",
        "print(data['v2'].head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before preprocessing: \n",
            "\n",
            "0    Go until jurong point, crazy.. Available only ...\n",
            "1                        Ok lar... Joking wif u oni...\n",
            "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3    U dun say so early hor... U c already then say...\n",
            "4    Nah I don't think he goes to usf, he lives aro...\n",
            "Name: v2, dtype: object\n",
            "\n",
            " After preprocessing: \n",
            "\n",
            "0    go until jurong point crazy available only in ...\n",
            "1                              ok lar joking wif u oni\n",
            "2    free entry in 2 a wkly comp to win fa cup fina...\n",
            "3          u dun say so early hor u c already then say\n",
            "4    nah i dont think he goes to usf he lives aroun...\n",
            "Name: v2, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQWg-cEMAlOG"
      },
      "source": [
        "# Fixing the maxFeatures as 2000 because of computation capabilities\n",
        "maxFeatures = 2000\n",
        "# Tokenizing the data\n",
        "tokenizer = Tokenizer(num_words=maxFeatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['v2'].values)\n",
        "# Converting into vector \n",
        "X = tokenizer.texts_to_sequences(data['v2'].values)\n",
        "# padding zero's if the sentence is small, to make each vector of same size.\n",
        "X = pad_sequences(X)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72biHn3K3MoT",
        "outputId": "0acfcfcb-e7a8-4421-f7fa-c0179fd036bb"
      },
      "source": [
        "# Finding the vector length\n",
        "print(X.shape)\n",
        "senLength = X.shape[1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572, 152)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehEOMrFqybjZ"
      },
      "source": [
        "# Defining the embeddingLayer dimension and Lstm nodes\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "# Function to create the model\n",
        "def createModel():\n",
        "    # Defining the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(maxFeatures, embed_dim, input_length=X.shape[1])) # Embedding layer\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) # LSTM layer\n",
        "    model.add(Dense(2, activation='sigmoid')) # Fully connected layer\n",
        "    # categorical_crossentropy as the loss function since dealing with 3 categorical data.\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akNSvh07y0S2"
      },
      "source": [
        "# Converting the lables into numerical format\n",
        "labelEncoder = LabelEncoder()\n",
        "integerEncoded = labelEncoder.fit_transform(data['v1'])\n",
        "# Converting these numerical format into One-hot encoding\n",
        "y = to_categorical(integerEncoded)\n",
        "# Splitting the data into training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPT43gSPzCNO",
        "outputId": "4b12cc92-d21f-43b2-e6b4-520d479206df"
      },
      "source": [
        "# Model summary\n",
        "model = createModel()\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 152, 128)          256000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 394       \n",
            "=================================================================\n",
            "Total params: 511,194\n",
            "Trainable params: 511,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOz3CQUhy-IK",
        "outputId": "d9a3faae-ddcc-46cb-dffb-abf0272ac26a"
      },
      "source": [
        "# Training the model for 10 epochs with batch size of 32.\n",
        "batch_size = 32\n",
        "model.fit(X_train, Y_train, epochs=5, batch_size=batch_size, verbose=2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "117/117 - 56s - loss: 0.2215 - accuracy: 0.9314\n",
            "Epoch 2/5\n",
            "117/117 - 55s - loss: 0.0434 - accuracy: 0.9863\n",
            "Epoch 3/5\n",
            "117/117 - 54s - loss: 0.0237 - accuracy: 0.9917\n",
            "Epoch 4/5\n",
            "117/117 - 54s - loss: 0.0154 - accuracy: 0.9965\n",
            "Epoch 5/5\n",
            "117/117 - 54s - loss: 0.0061 - accuracy: 0.9981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc78e134310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2HzmwbX04RL"
      },
      "source": [
        "# Saving the Model\n",
        "model.save(\"/content/gdrive/MyDrive/Deep Learning/ICP12/spamModel.h5\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puXNkCPP1Blr",
        "outputId": "ef640ea1-defe-411a-de43-276999104bed"
      },
      "source": [
        "# Loading the saved model\n",
        "savedModel = load_model('/content/gdrive/MyDrive/Deep Learning/ICP12/spamModel.h5')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH1mOIm34nf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74319589-552a-45fe-f009-11a91ba03988"
      },
      "source": [
        "# Model Prediction on test dataset\n",
        "score, acc = savedModel.evaluate(X_test, Y_test, verbose=2, batch_size=batch_size)\n",
        "print(\"Score: \",score,\"  Accuracy: \",acc)\n",
        "print(\"Metrics\",model.metrics_names)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58/58 - 2s - loss: 0.0900 - accuracy: 0.9810\n",
            "Score:  0.09004170447587967   Accuracy:  0.9809679388999939\n",
            "Metrics ['loss', 'accuracy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITts-ecgpxzW",
        "outputId": "bfa7b02d-f7d6-47ff-eccb-ba514ac4f8f4"
      },
      "source": [
        "# Grid Search\n",
        "model = KerasClassifier(build_fn=createModel,verbose=2)\n",
        "# Defining the batchsize and epoch. To find which batchsize and epochs is correct.\n",
        "batch_size= [32, 64]\n",
        "epochs = [2, 3]\n",
        "param_grid= dict(batch_size=batch_size, epochs=epochs)\n",
        "# Defining the GridSearch\n",
        "grid  = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "# Fitting on training dataset and finding the best parameters\n",
        "grid_result= grid.fit(X_train, y=Y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "94/94 - 47s - loss: 0.2137 - accuracy: 0.9324\n",
            "Epoch 2/2\n",
            "94/94 - 44s - loss: 0.0466 - accuracy: 0.9866\n",
            "24/24 - 1s - loss: 0.0572 - accuracy: 0.9839\n",
            "Epoch 1/2\n",
            "94/94 - 46s - loss: 0.2095 - accuracy: 0.9270\n",
            "Epoch 2/2\n",
            "94/94 - 46s - loss: 0.0524 - accuracy: 0.9856\n",
            "24/24 - 1s - loss: 0.0519 - accuracy: 0.9839\n",
            "Epoch 1/2\n",
            "94/94 - 47s - loss: 0.2265 - accuracy: 0.9230\n",
            "Epoch 2/2\n",
            "94/94 - 45s - loss: 0.0471 - accuracy: 0.9859\n",
            "24/24 - 1s - loss: 0.1008 - accuracy: 0.9719\n",
            "Epoch 1/2\n",
            "94/94 - 48s - loss: 0.2626 - accuracy: 0.9136\n",
            "Epoch 2/2\n",
            "94/94 - 45s - loss: 0.0551 - accuracy: 0.9839\n",
            "24/24 - 1s - loss: 0.0542 - accuracy: 0.9839\n",
            "Epoch 1/2\n",
            "94/94 - 47s - loss: 0.2508 - accuracy: 0.9136\n",
            "Epoch 2/2\n",
            "94/94 - 45s - loss: 0.0512 - accuracy: 0.9856\n",
            "24/24 - 1s - loss: 0.0579 - accuracy: 0.9759\n",
            "Epoch 1/3\n",
            "94/94 - 47s - loss: 0.2328 - accuracy: 0.9233\n",
            "Epoch 2/3\n",
            "94/94 - 45s - loss: 0.0489 - accuracy: 0.9849\n",
            "Epoch 3/3\n",
            "94/94 - 45s - loss: 0.0312 - accuracy: 0.9923\n",
            "24/24 - 1s - loss: 0.0577 - accuracy: 0.9826\n",
            "Epoch 1/3\n",
            "94/94 - 46s - loss: 0.2293 - accuracy: 0.9236\n",
            "Epoch 2/3\n",
            "94/94 - 44s - loss: 0.0541 - accuracy: 0.9819\n",
            "Epoch 3/3\n",
            "94/94 - 44s - loss: 0.0277 - accuracy: 0.9926\n",
            "24/24 - 1s - loss: 0.0464 - accuracy: 0.9853\n",
            "Epoch 1/3\n",
            "94/94 - 47s - loss: 0.2094 - accuracy: 0.9310\n",
            "Epoch 2/3\n",
            "94/94 - 44s - loss: 0.0427 - accuracy: 0.9873\n",
            "Epoch 3/3\n",
            "94/94 - 45s - loss: 0.0217 - accuracy: 0.9940\n",
            "24/24 - 1s - loss: 0.0907 - accuracy: 0.9772\n",
            "Epoch 1/3\n",
            "94/94 - 46s - loss: 0.2426 - accuracy: 0.9156\n",
            "Epoch 2/3\n",
            "94/94 - 44s - loss: 0.0548 - accuracy: 0.9849\n",
            "Epoch 3/3\n",
            "94/94 - 44s - loss: 0.0291 - accuracy: 0.9916\n",
            "24/24 - 1s - loss: 0.0629 - accuracy: 0.9799\n",
            "Epoch 1/3\n",
            "94/94 - 45s - loss: 0.2105 - accuracy: 0.9307\n",
            "Epoch 2/3\n",
            "94/94 - 43s - loss: 0.0463 - accuracy: 0.9869\n",
            "Epoch 3/3\n",
            "94/94 - 43s - loss: 0.0248 - accuracy: 0.9936\n",
            "24/24 - 1s - loss: 0.0908 - accuracy: 0.9745\n",
            "Epoch 1/2\n",
            "47/47 - 26s - loss: 0.3605 - accuracy: 0.8761\n",
            "Epoch 2/2\n",
            "47/47 - 24s - loss: 0.0709 - accuracy: 0.9789\n",
            "12/12 - 1s - loss: 0.0649 - accuracy: 0.9813\n",
            "Epoch 1/2\n",
            "47/47 - 25s - loss: 0.3722 - accuracy: 0.8811\n",
            "Epoch 2/2\n",
            "47/47 - 23s - loss: 0.0843 - accuracy: 0.9756\n",
            "12/12 - 1s - loss: 0.0540 - accuracy: 0.9813\n",
            "Epoch 1/2\n",
            "47/47 - 26s - loss: 0.3104 - accuracy: 0.8938\n",
            "Epoch 2/2\n",
            "47/47 - 23s - loss: 0.0741 - accuracy: 0.9779\n",
            "12/12 - 1s - loss: 0.0756 - accuracy: 0.9759\n",
            "Epoch 1/2\n",
            "47/47 - 27s - loss: 0.3631 - accuracy: 0.8775\n",
            "Epoch 2/2\n",
            "47/47 - 23s - loss: 0.0783 - accuracy: 0.9779\n",
            "12/12 - 1s - loss: 0.0789 - accuracy: 0.9718\n",
            "Epoch 1/2\n",
            "47/47 - 25s - loss: 0.3150 - accuracy: 0.8925\n",
            "Epoch 2/2\n",
            "47/47 - 23s - loss: 0.0681 - accuracy: 0.9819\n",
            "12/12 - 1s - loss: 0.0586 - accuracy: 0.9772\n",
            "Epoch 1/3\n",
            "47/47 - 26s - loss: 0.3219 - accuracy: 0.8891\n",
            "Epoch 2/3\n",
            "47/47 - 24s - loss: 0.0675 - accuracy: 0.9812\n",
            "Epoch 3/3\n",
            "47/47 - 23s - loss: 0.0363 - accuracy: 0.9889\n",
            "12/12 - 1s - loss: 0.0763 - accuracy: 0.9813\n",
            "Epoch 1/3\n",
            "47/47 - 26s - loss: 0.3044 - accuracy: 0.8969\n",
            "Epoch 2/3\n",
            "47/47 - 23s - loss: 0.0683 - accuracy: 0.9809\n",
            "Epoch 3/3\n",
            "47/47 - 23s - loss: 0.0335 - accuracy: 0.9906\n",
            "12/12 - 1s - loss: 0.0634 - accuracy: 0.9813\n",
            "Epoch 1/3\n",
            "47/47 - 26s - loss: 0.3638 - accuracy: 0.8714\n",
            "Epoch 2/3\n",
            "47/47 - 24s - loss: 0.0705 - accuracy: 0.9802\n",
            "Epoch 3/3\n",
            "47/47 - 24s - loss: 0.0351 - accuracy: 0.9910\n",
            "12/12 - 1s - loss: 0.0724 - accuracy: 0.9786\n",
            "Epoch 1/3\n",
            "47/47 - 26s - loss: 0.3021 - accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "47/47 - 24s - loss: 0.0664 - accuracy: 0.9802\n",
            "Epoch 3/3\n",
            "47/47 - 24s - loss: 0.0345 - accuracy: 0.9896\n",
            "12/12 - 1s - loss: 0.0737 - accuracy: 0.9799\n",
            "Epoch 1/3\n",
            "47/47 - 26s - loss: 0.3394 - accuracy: 0.8828\n",
            "Epoch 2/3\n",
            "47/47 - 24s - loss: 0.0711 - accuracy: 0.9782\n",
            "Epoch 3/3\n",
            "47/47 - 25s - loss: 0.0393 - accuracy: 0.9883\n",
            "12/12 - 1s - loss: 0.0576 - accuracy: 0.9786\n",
            "Epoch 1/2\n",
            "117/117 - 59s - loss: 0.2574 - accuracy: 0.9137\n",
            "Epoch 2/2\n",
            "117/117 - 56s - loss: 0.0475 - accuracy: 0.9861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K2w9hzYssqe",
        "outputId": "39b54220-7319-42b8-acd3-167d38ee22aa"
      },
      "source": [
        "# Summarize results from grid serach\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.979909 using {'batch_size': 32, 'epochs': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLfCrhEG3L37"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}