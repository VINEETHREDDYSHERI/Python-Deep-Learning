{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP12-Question2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGKoOYBHyWTQ"
      },
      "source": [
        "# Importing the necessary libraries\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVK2XutLzfso",
        "outputId": "2bc9b3b0-7f16-45e6-e664-fcbdf014cfe4"
      },
      "source": [
        "# Connecting to google drive for accessing the Sentiment.csv and also to save model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVW03eHLxr8-",
        "outputId": "57fa7e08-9407-4f78-9a6a-3314fc5859e1"
      },
      "source": [
        "# Loading the Sentiment dataset\n",
        "data = pd.read_csv('/content/gdrive/MyDrive/Deep Learning/ICP12/Sentiment.csv')\n",
        "\n",
        "# Keeping only the columns that are required. Text is input and Sentiment is the output.\n",
        "data = data[['text', 'sentiment']]\n",
        "\n",
        "print(\"Before preprocessing: \\n\")\n",
        "print(data['text'].head())\n",
        "# Applying pre-processing task\n",
        "# Converting all the characters to lower case\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "# Making using of Regular expression to remove unwanted data like @ / ' # . etc.\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n",
        "\n",
        "# Removing 'rt' string that is persent in all the text.\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')\n",
        "\n",
        "print(\"\\n After preprocessing: \\n\")\n",
        "print(data['text'].head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before preprocessing: \n",
            "\n",
            "0    RT @NancyLeeGrahn: How did everyone feel about...\n",
            "1    RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
            "2    RT @TJMShow: No mention of Tamir Rice and the ...\n",
            "3    RT @RobGeorge: That Carly Fiorina is trending ...\n",
            "4    RT @DanScavino: #GOPDebate w/ @realDonaldTrump...\n",
            "Name: text, dtype: object\n",
            "\n",
            " After preprocessing: \n",
            "\n",
            "0      nancyleegrahn how did everyone feel about th...\n",
            "1      scottwalker didnt catch the full gopdebate l...\n",
            "2      tjmshow no mention of tamir rice and the gop...\n",
            "3      robgeorge that carly fiorina is trending  ho...\n",
            "4      danscavino gopdebate w realdonaldtrump deliv...\n",
            "Name: text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQWg-cEMAlOG"
      },
      "source": [
        "# Fixing the maxFeatures as 2000 because of computation capabilities\n",
        "maxFeatures = 2000\n",
        "# Tokenizing the data\n",
        "tokenizer = Tokenizer(num_words=maxFeatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "# Converting into vector \n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "# padding zero's if the sentence is small, to make each vector of same size.\n",
        "X = pad_sequences(X)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehEOMrFqybjZ"
      },
      "source": [
        "# Defining the embeddingLayer dimension and Lstm nodes\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "# Function to create the model\n",
        "def createModel():\n",
        "    # Defining the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(maxFeatures, embed_dim, input_length=X.shape[1])) # Embedding layer\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) # LSTM layer\n",
        "    model.add(Dense(3, activation='softmax')) # Fully connected layer\n",
        "    # categorical_crossentropy as the loss function since dealing with 3 categorical data.\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akNSvh07y0S2"
      },
      "source": [
        "# Converting the lables into numerical format\n",
        "labelEncoder = LabelEncoder()\n",
        "integerEncoded = labelEncoder.fit_transform(data['sentiment'])\n",
        "# Converting these numerical format into One-hot encoding\n",
        "y = to_categorical(integerEncoded)\n",
        "# Splitting the data into training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPT43gSPzCNO",
        "outputId": "8445dec6-393b-4ec1-d280-321af9a50c10"
      },
      "source": [
        "# Model summary\n",
        "model = createModel()\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 28, 128)           256000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 591       \n",
            "=================================================================\n",
            "Total params: 511,391\n",
            "Trainable params: 511,391\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH1mOIm34nf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec56d941-4d2d-49f2-e808-0e37c420226e"
      },
      "source": [
        "# Grid Search\n",
        "model = KerasClassifier(build_fn=createModel,verbose=2)\n",
        "# Defining the batchsize and epoch. To find which batchsize and epochs is correct.\n",
        "batch_size= [16, 32, 64]\n",
        "epochs = [1, 2, 3]\n",
        "param_grid= dict(batch_size=batch_size, epochs=epochs)\n",
        "# Defining the GridSearch\n",
        "grid  = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "# Fitting on training dataset and finding the best parameters\n",
        "grid_result= grid.fit(X_train, y=Y_train)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "465/465 - 47s - loss: 0.8313 - accuracy: 0.6464\n",
            "117/117 - 1s - loss: 0.7460 - accuracy: 0.6783\n",
            "465/465 - 48s - loss: 0.8244 - accuracy: 0.6476\n",
            "117/117 - 1s - loss: 0.7871 - accuracy: 0.6665\n",
            "465/465 - 47s - loss: 0.8296 - accuracy: 0.6455\n",
            "117/117 - 1s - loss: 0.7593 - accuracy: 0.6767\n",
            "465/465 - 49s - loss: 0.8228 - accuracy: 0.6440\n",
            "117/117 - 1s - loss: 0.7641 - accuracy: 0.6738\n",
            "465/465 - 47s - loss: 0.8253 - accuracy: 0.6438\n",
            "117/117 - 1s - loss: 0.7885 - accuracy: 0.6722\n",
            "Epoch 1/2\n",
            "465/465 - 48s - loss: 0.8325 - accuracy: 0.6410\n",
            "Epoch 2/2\n",
            "465/465 - 45s - loss: 0.6842 - accuracy: 0.7077\n",
            "117/117 - 1s - loss: 0.7375 - accuracy: 0.6875\n",
            "Epoch 1/2\n",
            "465/465 - 48s - loss: 0.8332 - accuracy: 0.6406\n",
            "Epoch 2/2\n",
            "465/465 - 45s - loss: 0.6891 - accuracy: 0.7136\n",
            "117/117 - 1s - loss: 0.7364 - accuracy: 0.6869\n",
            "Epoch 1/2\n",
            "465/465 - 49s - loss: 0.8290 - accuracy: 0.6408\n",
            "Epoch 2/2\n",
            "465/465 - 47s - loss: 0.6775 - accuracy: 0.7135\n",
            "117/117 - 1s - loss: 0.7442 - accuracy: 0.6869\n",
            "Epoch 1/2\n",
            "465/465 - 47s - loss: 0.8305 - accuracy: 0.6414\n",
            "Epoch 2/2\n",
            "465/465 - 46s - loss: 0.6760 - accuracy: 0.7177\n",
            "117/117 - 1s - loss: 0.7538 - accuracy: 0.6787\n",
            "Epoch 1/2\n",
            "465/465 - 49s - loss: 0.8236 - accuracy: 0.6387\n",
            "Epoch 2/2\n",
            "465/465 - 46s - loss: 0.6704 - accuracy: 0.7110\n",
            "117/117 - 1s - loss: 0.7684 - accuracy: 0.6625\n",
            "Epoch 1/3\n",
            "465/465 - 48s - loss: 0.8291 - accuracy: 0.6437\n",
            "Epoch 2/3\n",
            "465/465 - 45s - loss: 0.6875 - accuracy: 0.7077\n",
            "Epoch 3/3\n",
            "465/465 - 45s - loss: 0.5990 - accuracy: 0.7468\n",
            "117/117 - 1s - loss: 0.7635 - accuracy: 0.6708\n",
            "Epoch 1/3\n",
            "465/465 - 48s - loss: 0.8314 - accuracy: 0.6439\n",
            "Epoch 2/3\n",
            "465/465 - 46s - loss: 0.6879 - accuracy: 0.7105\n",
            "Epoch 3/3\n",
            "465/465 - 45s - loss: 0.6039 - accuracy: 0.7486\n",
            "117/117 - 1s - loss: 0.7569 - accuracy: 0.6778\n",
            "Epoch 1/3\n",
            "465/465 - 48s - loss: 0.8348 - accuracy: 0.6353\n",
            "Epoch 2/3\n",
            "465/465 - 46s - loss: 0.6822 - accuracy: 0.7107\n",
            "Epoch 3/3\n",
            "465/465 - 46s - loss: 0.6033 - accuracy: 0.7513\n",
            "117/117 - 1s - loss: 0.7664 - accuracy: 0.6842\n",
            "Epoch 1/3\n",
            "465/465 - 49s - loss: 0.8303 - accuracy: 0.6464\n",
            "Epoch 2/3\n",
            "465/465 - 47s - loss: 0.6750 - accuracy: 0.7112\n",
            "Epoch 3/3\n",
            "465/465 - 46s - loss: 0.5985 - accuracy: 0.7447\n",
            "117/117 - 1s - loss: 0.7883 - accuracy: 0.6658\n",
            "Epoch 1/3\n",
            "465/465 - 48s - loss: 0.8188 - accuracy: 0.6487\n",
            "Epoch 2/3\n",
            "465/465 - 46s - loss: 0.6746 - accuracy: 0.7114\n",
            "Epoch 3/3\n",
            "465/465 - 46s - loss: 0.5924 - accuracy: 0.7571\n",
            "117/117 - 1s - loss: 0.8464 - accuracy: 0.6733\n",
            "233/233 - 25s - loss: 0.8405 - accuracy: 0.6402\n",
            "59/59 - 1s - loss: 0.7807 - accuracy: 0.6471\n",
            "233/233 - 25s - loss: 0.8373 - accuracy: 0.6407\n",
            "59/59 - 1s - loss: 0.7763 - accuracy: 0.6520\n",
            "233/233 - 25s - loss: 0.8414 - accuracy: 0.6361\n",
            "59/59 - 1s - loss: 0.7541 - accuracy: 0.6805\n",
            "233/233 - 25s - loss: 0.8456 - accuracy: 0.6363\n",
            "59/59 - 1s - loss: 0.7605 - accuracy: 0.6733\n",
            "233/233 - 25s - loss: 0.8364 - accuracy: 0.6402\n",
            "59/59 - 1s - loss: 0.7634 - accuracy: 0.6744\n",
            "Epoch 1/2\n",
            "233/233 - 25s - loss: 0.8416 - accuracy: 0.6394\n",
            "Epoch 2/2\n",
            "233/233 - 23s - loss: 0.6883 - accuracy: 0.7043\n",
            "59/59 - 1s - loss: 0.7316 - accuracy: 0.6821\n",
            "Epoch 1/2\n",
            "233/233 - 25s - loss: 0.8288 - accuracy: 0.6441\n",
            "Epoch 2/2\n",
            "233/233 - 23s - loss: 0.6848 - accuracy: 0.7108\n",
            "59/59 - 1s - loss: 0.7410 - accuracy: 0.6821\n",
            "Epoch 1/2\n",
            "233/233 - 25s - loss: 0.8453 - accuracy: 0.6297\n",
            "Epoch 2/2\n",
            "233/233 - 23s - loss: 0.6859 - accuracy: 0.7164\n",
            "59/59 - 1s - loss: 0.7379 - accuracy: 0.6869\n",
            "Epoch 1/2\n",
            "233/233 - 25s - loss: 0.8448 - accuracy: 0.6375\n",
            "Epoch 2/2\n",
            "233/233 - 23s - loss: 0.6879 - accuracy: 0.7071\n",
            "59/59 - 1s - loss: 0.7510 - accuracy: 0.6609\n",
            "Epoch 1/2\n",
            "233/233 - 24s - loss: 0.8316 - accuracy: 0.6414\n",
            "Epoch 2/2\n",
            "233/233 - 23s - loss: 0.6733 - accuracy: 0.7120\n",
            "59/59 - 1s - loss: 0.7721 - accuracy: 0.6679\n",
            "Epoch 1/3\n",
            "233/233 - 25s - loss: 0.8457 - accuracy: 0.6403\n",
            "Epoch 2/3\n",
            "233/233 - 23s - loss: 0.6935 - accuracy: 0.7007\n",
            "Epoch 3/3\n",
            "233/233 - 23s - loss: 0.6176 - accuracy: 0.7429\n",
            "59/59 - 1s - loss: 0.7504 - accuracy: 0.6713\n",
            "Epoch 1/3\n",
            "233/233 - 24s - loss: 0.8398 - accuracy: 0.6384\n",
            "Epoch 2/3\n",
            "233/233 - 22s - loss: 0.6947 - accuracy: 0.7066\n",
            "Epoch 3/3\n",
            "233/233 - 22s - loss: 0.6170 - accuracy: 0.7408\n",
            "59/59 - 1s - loss: 0.7308 - accuracy: 0.6853\n",
            "Epoch 1/3\n",
            "233/233 - 25s - loss: 0.8421 - accuracy: 0.6326\n",
            "Epoch 2/3\n",
            "233/233 - 22s - loss: 0.6891 - accuracy: 0.7037\n",
            "Epoch 3/3\n",
            "233/233 - 22s - loss: 0.6108 - accuracy: 0.7398\n",
            "59/59 - 1s - loss: 0.7559 - accuracy: 0.6815\n",
            "Epoch 1/3\n",
            "233/233 - 25s - loss: 0.8393 - accuracy: 0.6412\n",
            "Epoch 2/3\n",
            "233/233 - 23s - loss: 0.6816 - accuracy: 0.7079\n",
            "Epoch 3/3\n",
            "233/233 - 23s - loss: 0.6032 - accuracy: 0.7432\n",
            "59/59 - 1s - loss: 0.7598 - accuracy: 0.6857\n",
            "Epoch 1/3\n",
            "233/233 - 25s - loss: 0.8366 - accuracy: 0.6406\n",
            "Epoch 2/3\n",
            "233/233 - 22s - loss: 0.6775 - accuracy: 0.7126\n",
            "Epoch 3/3\n",
            "233/233 - 23s - loss: 0.5981 - accuracy: 0.7506\n",
            "59/59 - 1s - loss: 0.8374 - accuracy: 0.6717\n",
            "117/117 - 14s - loss: 0.8654 - accuracy: 0.6240\n",
            "30/30 - 1s - loss: 0.7675 - accuracy: 0.6622\n",
            "117/117 - 14s - loss: 0.8531 - accuracy: 0.6282\n",
            "30/30 - 1s - loss: 0.8880 - accuracy: 0.6374\n",
            "117/117 - 14s - loss: 0.8593 - accuracy: 0.6227\n",
            "30/30 - 1s - loss: 0.7926 - accuracy: 0.6638\n",
            "117/117 - 14s - loss: 0.8644 - accuracy: 0.6241\n",
            "30/30 - 1s - loss: 0.7636 - accuracy: 0.6728\n",
            "117/117 - 14s - loss: 0.8633 - accuracy: 0.6281\n",
            "30/30 - 1s - loss: 0.7911 - accuracy: 0.6706\n",
            "Epoch 1/2\n",
            "117/117 - 14s - loss: 0.8679 - accuracy: 0.6330\n",
            "Epoch 2/2\n",
            "117/117 - 12s - loss: 0.7029 - accuracy: 0.7029\n",
            "30/30 - 1s - loss: 0.7539 - accuracy: 0.6740\n",
            "Epoch 1/2\n",
            "117/117 - 14s - loss: 0.8642 - accuracy: 0.6267\n",
            "Epoch 2/2\n",
            "117/117 - 12s - loss: 0.7007 - accuracy: 0.6994\n",
            "30/30 - 1s - loss: 0.7726 - accuracy: 0.6789\n",
            "Epoch 1/2\n",
            "117/117 - 14s - loss: 0.8580 - accuracy: 0.6305\n",
            "Epoch 2/2\n",
            "117/117 - 12s - loss: 0.7006 - accuracy: 0.7007\n",
            "30/30 - 1s - loss: 0.7459 - accuracy: 0.6837\n",
            "Epoch 1/2\n",
            "117/117 - 14s - loss: 0.8798 - accuracy: 0.6218\n",
            "Epoch 2/2\n",
            "117/117 - 12s - loss: 0.7028 - accuracy: 0.6991\n",
            "30/30 - 1s - loss: 0.7436 - accuracy: 0.6733\n",
            "Epoch 1/2\n",
            "117/117 - 14s - loss: 0.8757 - accuracy: 0.6215\n",
            "Epoch 2/2\n",
            "117/117 - 13s - loss: 0.6965 - accuracy: 0.6972\n",
            "30/30 - 1s - loss: 0.7805 - accuracy: 0.6717\n",
            "Epoch 1/3\n",
            "117/117 - 14s - loss: 0.8692 - accuracy: 0.6244\n",
            "Epoch 2/3\n",
            "117/117 - 12s - loss: 0.7086 - accuracy: 0.6981\n",
            "Epoch 3/3\n",
            "117/117 - 12s - loss: 0.6272 - accuracy: 0.7368\n",
            "30/30 - 1s - loss: 0.7286 - accuracy: 0.6783\n",
            "Epoch 1/3\n",
            "117/117 - 14s - loss: 0.8645 - accuracy: 0.6271\n",
            "Epoch 2/3\n",
            "117/117 - 12s - loss: 0.7040 - accuracy: 0.7014\n",
            "Epoch 3/3\n",
            "117/117 - 12s - loss: 0.6245 - accuracy: 0.7369\n",
            "30/30 - 1s - loss: 0.7604 - accuracy: 0.6864\n",
            "Epoch 1/3\n",
            "117/117 - 14s - loss: 0.8723 - accuracy: 0.6229\n",
            "Epoch 2/3\n",
            "117/117 - 12s - loss: 0.7154 - accuracy: 0.6975\n",
            "Epoch 3/3\n",
            "117/117 - 12s - loss: 0.6250 - accuracy: 0.7351\n",
            "30/30 - 1s - loss: 0.7534 - accuracy: 0.6902\n",
            "Epoch 1/3\n",
            "117/117 - 14s - loss: 0.8655 - accuracy: 0.6231\n",
            "Epoch 2/3\n",
            "117/117 - 12s - loss: 0.7025 - accuracy: 0.6980\n",
            "Epoch 3/3\n",
            "117/117 - 12s - loss: 0.6197 - accuracy: 0.7377\n",
            "30/30 - 1s - loss: 0.7516 - accuracy: 0.6803\n",
            "Epoch 1/3\n",
            "117/117 - 14s - loss: 0.8719 - accuracy: 0.6269\n",
            "Epoch 2/3\n",
            "117/117 - 12s - loss: 0.6916 - accuracy: 0.7045\n",
            "Epoch 3/3\n",
            "117/117 - 12s - loss: 0.6080 - accuracy: 0.7450\n",
            "30/30 - 1s - loss: 0.7918 - accuracy: 0.6674\n",
            "Epoch 1/3\n",
            "146/146 - 17s - loss: 0.8422 - accuracy: 0.6367\n",
            "Epoch 2/3\n",
            "146/146 - 15s - loss: 0.6864 - accuracy: 0.7069\n",
            "Epoch 3/3\n",
            "146/146 - 15s - loss: 0.6176 - accuracy: 0.7368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ig7yErTLcej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b743ce-2257-4ed5-860d-0434b9868489"
      },
      "source": [
        "# Summarize results from grid serach\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.680511 using {'batch_size': 64, 'epochs': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2M_4cNtHlEZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}